{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr+nUCTFCaNSA6DpzTApHy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandreimircea/PhDWork-ML-DL-/blob/main/LipidomicsEATModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQkCpR_XDwxC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ObeseVsNormal"
      ],
      "metadata": {
        "id": "fPXE4iCgLUTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_lipids = ['PI(16:0/20:3)','TAG54:5-FA16:1','TAG54:5-FA20:4','TAG54:5-FA22:4','TAG56:6-FA22:4','TAG56:6-FA16:0','TAG56:5-FA22:5','TAG54:5-FA16:0','TAG56:5-FA20:4','TAG56:5-FA22:4','TAG52:5-FA20:3','TAG54:5-FA22:5','TAG56:6-FA18:0','TAG54:4-FA20:3','TAG52:4-FA22:4','PA(16:1/18:0)','TAG50:4-FA20:3','TAG56:6-FA22:5','TAG52:5-FA14:0','TAG56:5-FA16:0','TAG48:3-FA18:2','TAG48:4-FA12:0','TAG54:5-FA20:3','TAG52:5-FA20:5','TAG56:4-FA20:4','TAG50:4-FA16:0','TAG54:6-FA20:4','TAG56:4-FA22:4','TAG52:4-FA14:0','TAG54:4-FA16:0','TAG54:2-FA20:2','TAG48:1-FA12:0','TAG48:4-FA18:2','TAG50:6-FA20:4','TAG52:4-FA22:1','TAG52:6-FA20:5','TAG56:7-FA22:4','TAG56:4-FA16:0','TAG48:5-FA18:3','TAG56:7-FA22:5','TAG56:6-FA18:2','TAG48:3-FA12:0','TAG52:5-FA16:1','TAG48:4-FA14:1','TAG50:3-FA18:2','TAG52:5-FA20:4','TAG56:5-FA18:1','TAG52:4-FA18:2','TAG56:5-FA18:0','TAG52:0-FA18:0','PI(18:0/20:5)_2','TAG54:4-FA20:4','TAG52:4-FA20:3','TAG56:6-FA20:3','TAG48:4-FA18:3','TAG48:1-FA18:0','TAG56:6-FA18:1','TAG52:4-FA16:0','TAG48:2-FA18:0','TAG52:7-FA22:6','PI(18:0/20:5)','TAG52:3-FA18:2','TAG50:5-FA16:1','PE(P-18:0/16:1)','TAG52:1-FA18:0','TAG52:3-FA16:0','TAG48:0-FA16:0','TAG50:3-FA16:0','TAG48:3-FA18:1','TAG50:4-FA14:1','TAG52:5-FA18:2','TAG54:4-FA22:4','TAG48:2-FA12:0','TAG50:0-FA18:0','TAG52:1-FA18:1','TAG50:4-FA20:4','TAG50:4-FA16:1','TAG50:5-FA20:4','TAG54:0-FA18:0','TAG50:2-FA16:1','TAG50:3-FA20:3','TAG48:2-FA16:0','TAG54:6-FA16:1','TAG56:4-FA18:0','TAG48:2-FA18:2','TAG52:4-FA18:1','TAG56:6-FA20:4','FFA(22:6)','TAG50:0-FA16:0','TAG54:3-FA20:2','FFA(20:0)','TAG48:3-FA14:1','TAG48:2-FA18:1','TAG52:4-FA18:0','HCER(14:0)','TAG50:1-FA16:1','TAG48:1-FA16:1','TAG48:3-FA18:3','TAG54:1-FA18:0','TAG48:3-FA16:0','TAG48:1-FA14:0','TAG48:0-FA18:0','TAG50:3-FA16:1','TAG52:0-FA16:0','TAG52:3-FA18:1','TAG50:2-FA16:0','TAG52:1-FA16:0','DAG(16:0/18:2)','TAG50:1-FA18:1','TAG48:3-FA14:0','TAG52:4-FA20:0','TAG52:4-FA16:1','TAG52:4-FA18:3','TAG48:1-FA18:1','TAG48:0-FA14:0','TAG48:2-FA14:1','TAG54:5-FA20:2','TAG48:4-FA20:4','TAG52:2-FA18:2','TAG50:4-FA14:0','TAG52:1-FA20:1','TAG48:5-FA18:2','PI(16:0/18:2)','FFA(22:5)','TAG48:1-FA16:0','TAG52:4-FA20:2','TAG52:3-FA18:0','TAG54:1-FA20:1','TAG56:5-FA20:3','TAG50:2-FA18:1','TAG54:3-FA16:0','TAG56:3-FA20:2','TAG56:7-FA20:4','TAG56:6-FA20:2','TAG50:1-FA16:0','TAG54:2-FA20:1','TAG50:3-FA14:0','TAG56:7-FA20:3','TAG50:1-FA20:1','TAG50:4-FA18:2','TAG52:2-FA16:0','PI(16:0/20:4)_2','TAG50:1-FA18:0','TAG56:8-FA22:5','TAG52:3-FA18:3','TAG50:2-FA18:2','TAG50:2-FA18:0','TAG52:6-FA18:1','PI(16:1/18:2)_2','TAG48:4-FA18:1','TAG52:7-FA18:1','TAG48:4-FA16:1','TAG52:5-FA18:1','TAG52:3-FA16:1','TAG54:1-FA18:1','TAG48:2-FA14:0','TAG50:3-FA18:0','TAG56:7-FA16:1','TAG50:4-FA18:3','TAG52:2-FA16:1','TAG48:1-FA14:1','TAG48:3-FA16:1','TAG48:2-FA16:1','TAG56:7-FA16:0','TAG50:3-FA18:3','HCER(18:0)','TAG50:5-FA18:3','TAG52:2-FA18:0','TAG52:1-FA16:1','TAG50:3-FA18:1','LPE(20:2)','TAG54:4-FA16:1','TAG54:6-FA22:6','TAG50:0-FA14:0','TAG50:5-FA18:2','TAG54:5-FA18:1','TAG54:5-FA18:2','TAG54:2-FA16:0','TAG56:6-FA20:5','TAG50:2-FA14:0','TAG56:3-FA18:0','TAG50:5-FA14:0','FFA(13:0)','TAG56:5-FA18:2','TAG56:5-FA20:2','FFA(22:4)','TAG56:7-FA18:3','TAG54:2-FA18:0','TAG52:7-FA16:0','TAG54:4-FA20:1','TAG50:4-FA18:1','TAG54:4-FA18:1','FFA(22:0)','LPE(20:1)','TAG56:7-FA18:1','FFA(18:0)','HCER(20:0)','TAG54:2-FA18:1','TAG56:4-FA20:2','TAG56:2-FA18:0','TAG54:3-FA18:0']\n",
        "dataset_lipidomics_M = pd.read_excel('targeted_lipidomics_myocytes.xlsx').iloc[6:,:]\n",
        "dataset_lipidomics_A = pd.read_excel('targeted_lipidomics_adipose.xlsx').iloc[6:,:]\n",
        "dataset_lipidomics_M.columns = pd.read_excel('targeted_lipidomics_myocytes.xlsx').iloc[4,:]\n",
        "dataset_lipidomics_A.columns = pd.read_excel('targeted_lipidomics_adipose.xlsx').iloc[5,:]\n",
        "\n",
        "filtered_lipidomics_M = dataset_lipidomics_M[dataset_lipidomics_M['Original'].str.startswith(tuple(target_lipids), na=False)]\n",
        "filtered_lipidomics_A = dataset_lipidomics_A[dataset_lipidomics_A['Original ID'].str.startswith(tuple(target_lipids), na=False)]\n",
        "filtered_lipidomics_A.rename(columns={'Original ID':'Original'}, inplace=True)"
      ],
      "metadata": {
        "id": "E9TGJSFjEEvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_lipidomics = pd.merge(filtered_lipidomics_M, filtered_lipidomics_A, on=\"Original\")\n",
        "metabolomicsDGE = pd.read_excel('Metabolomics&DGEObeseVNormal.xlsx')\n",
        "metabolomicsDGE = metabolomicsDGE.T\n",
        "merged_lipidomics = merged_lipidomics.T\n",
        "metabolomicsDGE.rename(columns={0:'Original'}, inplace=True)\n",
        "dataset = pd.concat([merged_lipidomics, metabolomicsDGE], axis = 1)"
      ],
      "metadata": {
        "id": "wURWpCiaJ2gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MetabolomicsDGELipidsOverweightvNormal = dataset.to_excel('MetabolomicsDGELipidsObesevNormal.xlsx')"
      ],
      "metadata": {
        "id": "ORaCgM3IJAfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelling_dataset = pd.read_excel('MetabolomicsDGELipidsObesevNormal.xlsx').T\n",
        "target = modelling_dataset.iloc[-1, :]\n",
        "target = target.map({'NORMAL':0, 'OBESE':1})\n",
        "modelling_dataset = modelling_dataset.T.iloc[:,1:-1]\n",
        "modelling_dataset.columns = modelling_dataset.columns.astype(str)\n",
        "RFmodel = cross_val_score(RandomForestClassifier(), modelling_dataset, target, cv = 10)\n",
        "SVMmodel = cross_val_score(SVC(), modelling_dataset, target, cv = 10)\n",
        "LRmodel = cross_val_score(LogisticRegression(max_iter = 500), modelling_dataset, target, cv = 10)\n",
        "LDAmodel = cross_val_score(LinearDiscriminantAnalysis(), modelling_dataset, target, cv = 10)\n",
        "print(np.mean(RFmodel), np.mean(SVMmodel), np.mean(LRmodel), np.mean(LDAmodel))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrNyg8BqQHHG",
        "outputId": "530343d7-9233-4294-d451-d328fe16250b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.65 0.525 0.6900000000000001 0.6599999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overweight versus normal"
      ],
      "metadata": {
        "id": "1tQtJIaZSqHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_lipids = ['TAG56:5-FA18:0','FFA(15:0)','TAG54:4-FA18:0','TAG54:5-FA22:1','TAG54:3-FA18:0','TAG52:2-FA18:2','TAG54:3-FA18:2','TAG52:3-FA16:0','TAG54:4-FA18:2','TAG52:3-FA18:2','TAG54:5-FA18:0','TAG52:4-FA16:0','TAG54:5-FA18:2','TAG54:4-FA18:1','TAG56:4-FA18:0','TAG54:2-FA18:2','TAG50:2-FA18:2','TAG56:6-FA16:0','TAG56:6-FA18:0','TAG54:5-FA18:3','TAG52:4-FA18:3','TAG52:3-FA18:3','FFA(22:0)','TAG56:5-FA20:4','TAG56:5-FA18:2','TAG56:5-FA18:1','TAG50:2-FA18:0','TAG48:4-FA12:0','TAG56:6-FA22:5','TAG54:5-FA18:1','TAG52:4-FA20:0','TAG54:4-FA18:3','TAG56:5-FA20:2','TAG52:4-FA18:2','TAG52:2-FA18:0','TAG54:4-FA20:3','TAG48:5-FA18:3','TAG54:4-FA16:0','TAG56:5-FA22:5','TAG50:5-FA14:0','TAG52:3-FA18:1','FFA(20:0)','TAG52:7-FA18:1','TAG54:5-FA22:5','TAG50:3-FA18:0','TAG56:6-FA20:3','TAG54:5-FA16:0','TAG48:2-FA18:2','TAG48:1-FA12:0','TAG50:1-FA14:0','TAG48:4-FA18:2','TAG56:4-FA20:2','FFA(24:1)','FFA(22:6)','TAG56:6-FA18:2','TAG50:3-FA18:3','FFA(14:1)','TAG50:3-FA14:0','TAG50:0-FA16:0','TAG52:1-FA18:1','TAG50:4-FA14:0','TAG48:3-FA12:0','TAG54:2-FA18:0','TAG54:5-FA20:3','TAG52:3-FA18:0','TAG50:0-FA18:0','TAG48:5-FA18:2','TAG54:5-FA20:2','TAG56:7-FA20:3','TAG54:6-FA22:6','TAG52:1-FA18:0','TAG56:4-FA18:1','TAG56:5-FA20:3','TAG48:0-FA18:0','TAG56:7-FA22:5','TAG50:5-FA18:3','TAG56:8-FA18:2','TAG48:2-FA18:0','TAG54:3-FA18:1','TAG50:1-FA18:1','TAG52:5-FA14:0','TAG56:4-FA18:2','TAG48:0-FA14:0','TAG52:2-FA16:0','TAG56:6-FA20:2','TAG50:3-FA18:2']\n",
        "dataset_lipidomics_M = pd.read_excel('targeted_lipidomics_myocytes.xlsx', sheet_name = 'Data with IDs').iloc[6:,:]\n",
        "dataset_lipidomics_A = pd.read_excel('targeted_lipidomics_adipose.xlsx', sheet_name = 'Data with IDs').iloc[6:,:]\n",
        "dataset_lipidomics_M.columns = pd.read_excel('targeted_lipidomics_myocytes.xlsx', sheet_name = 'Data with IDs').iloc[4,:]\n",
        "dataset_lipidomics_A.columns = pd.read_excel('targeted_lipidomics_adipose.xlsx', sheet_name = 'Data with IDs').iloc[5,:]\n",
        "\n",
        "filtered_lipidomics_M = dataset_lipidomics_M[dataset_lipidomics_M['Original'].str.startswith(tuple(target_lipids), na=False)]\n",
        "filtered_lipidomics_A = dataset_lipidomics_A[dataset_lipidomics_A['Original ID'].str.startswith(tuple(target_lipids), na=False)]\n",
        "filtered_lipidomics_A.rename(columns={'Original ID':'Original'}, inplace=True)"
      ],
      "metadata": {
        "id": "xV1UzrPYSro5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c27b0451-b893-4cd5-a670-578c9b750433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-8d36381a3e11>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_lipidomics_A.rename(columns={'Original ID':'Original'}, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_lipidomics = pd.merge(filtered_lipidomics_M, filtered_lipidomics_A, on=\"Original\")\n",
        "metabolomicsDGE = pd.read_excel('Metabolomics&DGEOverweightvNormal.xlsx')\n",
        "metabolomicsDGE = metabolomicsDGE.T\n",
        "merged_lipidomics = merged_lipidomics.T\n",
        "metabolomicsDGE.rename(columns={0:'Original'}, inplace=True)\n",
        "dataset = pd.concat([merged_lipidomics, metabolomicsDGE], axis = 1)"
      ],
      "metadata": {
        "id": "kxajAXPuJKRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MetabolomicsDGELipidsOverweightvNormal = dataset.to_excel('MetabolomicsDGELipidsOverweightvNormal.xlsx')"
      ],
      "metadata": {
        "id": "HeX8pWV7JMaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelling_dataset = pd.read_excel('MetabolomicsDGELipidsOverweightvNormal.xlsx').T\n",
        "target = modelling_dataset.iloc[-1, :]\n",
        "target = target.map({'NORMAL':0, 'OVERWEIGHT':1})\n",
        "modelling_dataset = modelling_dataset.T.iloc[:,1:-1]\n",
        "modelling_dataset.columns = modelling_dataset.columns.astype(str)\n",
        "RFmodel = cross_val_score(RandomForestClassifier(), modelling_dataset, target, cv = 10)\n",
        "SVMmodel = cross_val_score(SVC(), modelling_dataset, target, cv = 10)\n",
        "LRmodel = cross_val_score(LogisticRegression(max_iter = 500), modelling_dataset, target, cv = 10)\n",
        "LDAmodel = cross_val_score(LinearDiscriminantAnalysis(), modelling_dataset, target, cv = 10)\n",
        "print(np.mean(RFmodel), np.mean(SVMmodel), np.mean(LRmodel), np.mean(LDAmodel))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc7UO5PsJOY7",
        "outputId": "1608c15e-c835-49a0-8902-6fea7562196c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.835 0.6900000000000001 0.805 0.905\n"
          ]
        }
      ]
    }
  ]
}